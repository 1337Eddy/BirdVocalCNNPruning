{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ead98b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import imageio\n",
    "import glob\n",
    "from collections import Counter\n",
    "from matplotlib.pyplot import hist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d947dcbf",
   "metadata": {},
   "source": [
    "Paths, Spectrogram Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c59f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'birdclef/'\n",
    "path_train_meta = path + 'train_metadata.csv'\n",
    "path_train_soundscape = path + 'train_soundscape_labels.csv'\n",
    "input_dir = path + 'train_short_audio/'\n",
    "output_dir = 'working/melspectrogram_dataset/'\n",
    "\n",
    "SAMPLE_RATE = 32000\n",
    "SIGNAL_LENGTH = 5 # seconds\n",
    "SPEC_SHAPE = (48, 128) # height x width\n",
    "FMIN = 500\n",
    "FMAX = 12500\n",
    "dimension = (48, 128, 1)\n",
    "SPEC_SHAPE = (48, 128)\n",
    "random_seed = 666\n",
    "\n",
    "model_name = 'models/TrainAudioOnly.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c6e43b",
   "metadata": {},
   "source": [
    "Prepare List of Birds which are trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c597872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soundscape ids controls which birds are taken from dataset \n",
    "soundscapes_ids = [28933, 42907]\n",
    "soundscapes = pd.read_csv('birdclef/train_soundscape_labels.csv',)\n",
    "soundscapes = soundscapes.query('audio_id in @soundscapes_ids')\n",
    "names = pd.unique(soundscapes['birds'])\n",
    "\n",
    "bird_list = []\n",
    "for i in range (0, len(names)):\n",
    "    split = names[i].split(' ')\n",
    "    bird_list = np.append(bird_list, split)\n",
    "    \n",
    "bird_list = np.unique(bird_list)\n",
    "bird_list = list(bird_list)\n",
    "bird_list.remove('nocall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db851b",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebff5f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 16291/19500 [00:19<00:03, 819.89it/s] \n"
     ]
    }
   ],
   "source": [
    "#bird_list = ['amerob', 'blujay', 'cangoo', 'gockin', 'norcar', 'rewbla', 'sonspa', 'swaspa']\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "distribution = [(bird, 0) for bird in bird_list]\n",
    "\n",
    "#specify the maximum of how many 5 second slides are taken to the train dataset for one bird\n",
    "num_spec_slices = 1500\n",
    "\n",
    "\n",
    "csv = pd.read_csv('birdclef/train_metadata.csv',)\n",
    "csv = csv.query('rating>=4')\n",
    "csv = csv.query('primary_label in @bird_list')\n",
    "\n",
    "csv_array = np.array(csv)\n",
    "\n",
    "old_bird_name = \"\"\n",
    "counter = 0\n",
    "\n",
    "with tqdm(total=len(bird_list)*num_spec_slices) as pbar:\n",
    "    #Go through lines of csv file\n",
    "    for i in range(0, len(csv)):      \n",
    "        bird_name = csv_array[i][0]\n",
    "        filename = csv_array[i][9][:-4]\n",
    "        index = bird_list.index(bird_name)\n",
    "        \n",
    "        if bird_name != old_bird_name:\n",
    "            counter = 0\n",
    "        old_bird_name = bird_name\n",
    "        \n",
    "        if counter >= num_spec_slices:\n",
    "            continue\n",
    "        \n",
    "        #Go through working directory and select 5s slices which belongs to actual audio file from csv\n",
    "        for spec in glob.glob(output_dir + bird_name + \"/\" + filename + \"*\"):\n",
    "            if counter >= num_spec_slices:\n",
    "                break           \n",
    "            im = imageio.imread(spec)\n",
    "            im = np.resize(im, dimension)\n",
    "            data.append(im)\n",
    "            zeros = np.zeros(len(bird_list))\n",
    "            zeros[index] = 1\n",
    "            labels.append(zeros)\n",
    "            counter += 1\n",
    "            pbar.update(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5323dc51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b14b64b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = shuffle(data, random_state=random_seed)\n",
    "labels = shuffle(labels, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4ea8e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL HAS 500733 PARAMETERS.\n"
     ]
    }
   ],
   "source": [
    "# Make sure your experiments are reproducible\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# Build a simple model as a sequence of  convolutional blocks.\n",
    "# Each block has the sequence CONV --> RELU --> BNORM --> MAXPOOL.\n",
    "# Finally, perform global average pooling and add 2 dense layers.\n",
    "# The last layer is our classification layer and is softmax activated.\n",
    "# (Well it's a multi-label task so sigmoid might actually be a better choice)\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # First conv block\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', \n",
    "                           input_shape=(SPEC_SHAPE[0], SPEC_SHAPE[1], 1)),\n",
    "    tf.keras.layers.BatchNormalization(),    \n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    " \n",
    "        \n",
    "    # Second conv block\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Third conv block\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)), \n",
    "    \n",
    "\n",
    "    \n",
    "    # Global pooling instead of flatten()\n",
    "    tf.keras.layers.Flatten(), \n",
    "    \n",
    "    # Dense block\n",
    "    tf.keras.layers.Dense(256, activation='relu'),   \n",
    "    tf.keras.layers.Dropout(0.5),      \n",
    "    tf.keras.layers.Dense(128, activation='relu'),   \n",
    "    tf.keras.layers.Dropout(0.5),  \n",
    "    \n",
    "    # Classification layer\n",
    "    tf.keras.layers.Dense(len(bird_list), activation='softmax')\n",
    "])\n",
    "print('MODEL HAS {} PARAMETERS.'.format(model.count_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1bf5b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 46, 126, 16)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 46, 126, 16)       64        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 124, 16)       2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 124, 16)       64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 62, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 60, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20, 60, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 58, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 18, 58, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 29, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 27, 64)         18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 27, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 5, 25, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 5, 25, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 12, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               393472    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 13)                1677      \n",
      "=================================================================\n",
      "Total params: 500,733\n",
      "Trainable params: 500,285\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39758bca",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11da7b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "label_smoothing = 0.1\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8d46b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=lr),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34b02f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                  patience=1, \n",
    "                                                  verbose=1, \n",
    "                                                  factor=0.5),\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              verbose=1,\n",
    "                                              patience=2),\n",
    "             tf.keras.callbacks.ModelCheckpoint(filepath=model_name, \n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=0,\n",
    "                                                save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd8d3fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "367/367 [==============================] - 37s 99ms/step - loss: 2.4487 - accuracy: 0.2139 - val_loss: 2.0452 - val_accuracy: 0.3737\n",
      "Epoch 2/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 2.0051 - accuracy: 0.3944 - val_loss: 1.7066 - val_accuracy: 0.5343\n",
      "Epoch 3/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 1.7894 - accuracy: 0.5077 - val_loss: 1.6089 - val_accuracy: 0.6055\n",
      "Epoch 4/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 1.6472 - accuracy: 0.5819 - val_loss: 1.4905 - val_accuracy: 0.6655\n",
      "Epoch 5/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 1.5487 - accuracy: 0.6305 - val_loss: 1.3876 - val_accuracy: 0.7017\n",
      "Epoch 6/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 1.4460 - accuracy: 0.6833 - val_loss: 1.4272 - val_accuracy: 0.6904\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 1.3258 - accuracy: 0.7339 - val_loss: 1.2308 - val_accuracy: 0.7583\n",
      "Epoch 8/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 1.2534 - accuracy: 0.7599 - val_loss: 1.1751 - val_accuracy: 0.7722\n",
      "Epoch 9/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 1.2133 - accuracy: 0.7806 - val_loss: 1.1815 - val_accuracy: 0.7828\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 1.1316 - accuracy: 0.8127 - val_loss: 1.0994 - val_accuracy: 0.8121\n",
      "Epoch 11/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 1.0918 - accuracy: 0.8325 - val_loss: 1.1756 - val_accuracy: 0.7740\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 12/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 1.0603 - accuracy: 0.8461 - val_loss: 1.0597 - val_accuracy: 0.8159\n",
      "Epoch 13/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 1.0350 - accuracy: 0.8552 - val_loss: 1.0465 - val_accuracy: 0.8237\n",
      "Epoch 14/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 1.0123 - accuracy: 0.8620 - val_loss: 1.0448 - val_accuracy: 0.8285\n",
      "Epoch 15/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 1.0013 - accuracy: 0.8716 - val_loss: 1.0543 - val_accuracy: 0.8207\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 16/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 0.9822 - accuracy: 0.8783 - val_loss: 1.0242 - val_accuracy: 0.8319\n",
      "Epoch 17/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 0.9707 - accuracy: 0.8826 - val_loss: 1.0224 - val_accuracy: 0.8326\n",
      "Epoch 18/25\n",
      "367/367 [==============================] - 36s 97ms/step - loss: 0.9593 - accuracy: 0.8857 - val_loss: 1.0169 - val_accuracy: 0.8363\n",
      "Epoch 19/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 0.9532 - accuracy: 0.8891 - val_loss: 1.0141 - val_accuracy: 0.8323\n",
      "Epoch 20/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 0.9423 - accuracy: 0.8909 - val_loss: 1.0074 - val_accuracy: 0.8391\n",
      "Epoch 21/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 0.9378 - accuracy: 0.8932 - val_loss: 1.0058 - val_accuracy: 0.8377\n",
      "Epoch 22/25\n",
      "367/367 [==============================] - 36s 97ms/step - loss: 0.9287 - accuracy: 0.8984 - val_loss: 1.0073 - val_accuracy: 0.8367\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 23/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 0.9218 - accuracy: 0.9013 - val_loss: 1.0054 - val_accuracy: 0.8387\n",
      "Epoch 24/25\n",
      "367/367 [==============================] - 36s 99ms/step - loss: 0.9170 - accuracy: 0.9042 - val_loss: 1.0015 - val_accuracy: 0.8336\n",
      "Epoch 25/25\n",
      "367/367 [==============================] - 36s 98ms/step - loss: 0.9105 - accuracy: 0.9073 - val_loss: 1.0035 - val_accuracy: 0.8363\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3749c84a00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = tf.keras.models.load_model(model_name)\n",
    "model.fit(np.array(data[:int(len(data)*0.9)]), \n",
    "          np.array(labels[:int(len(data)*0.9)]),\n",
    "          batch_size=batch_size,\n",
    "          validation_split=0.2,\n",
    "          callbacks=callbacks,\n",
    "          workers=16,\n",
    "          epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed8604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(arr):\n",
    "    return bird_list[np.argmax(arr)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352cf262",
   "metadata": {},
   "source": [
    "Prediction method: \n",
    "Insert index of train dataset and it predicts the bird "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4b7071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prediction(index=0):\n",
    "    input_bird = np.resize(data[index], (1, 48, 128, 1))\n",
    "    result = list(zip(bird_list, model.predict(input_bird)[0]*100))\n",
    "    return (prediction(labels[index]), result)\n",
    "\n",
    "eval_prediction(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08a5fbf",
   "metadata": {},
   "source": [
    "Plot the distribution of the bird dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(labels)\n",
    "unique, counts = np.unique(a, return_counts=True, axis=0)\n",
    "X = []\n",
    "for i in range(0, len(unique)):\n",
    "    X.append(prediction(unique[i]))\n",
    "\n",
    "\n",
    "plt.bar([x for x in range(0, len(counts))], counts, tick_label=X)\n",
    "plt.xticks(rotation=70)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
